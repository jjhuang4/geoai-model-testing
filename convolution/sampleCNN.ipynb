{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67b15a5d-2602-4912-b674-3b5cf1473c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the built in PyTorch MNIST dataset, we perform some transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bb898ec-3b9c-41f3-9369-8919f80d71a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 156439638.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 83484282.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 57982254.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 7427106.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = True,\n",
    "    transform = ToTensor(),\n",
    "    download = True,\n",
    ")\n",
    "test_data = datasets.MNIST(\n",
    "    root = 'data', \n",
    "    train = False,\n",
    "    transform = ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examining the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57cb6a65-df9c-4835-8dab-aa2cc30e5244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure = plt.figure(figsize=(10, 8))\n",
    "cols, rows = 5, 5\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(train_data), size=(1,)).item()\n",
    "    img, label = train_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(label)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataLoaders are necessary for letting the model process large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d99724e6-e386-45c7-af80-e3d21e2a097e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = {\n",
    "    'train' : torch.utils.data.DataLoader(train_data,\n",
    "                                          batch_size=100,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=1),\n",
    "    'test' : torch.utils.data.DataLoader(test_data,\n",
    "                                         batch_size=100,\n",
    "                                         shuffle=True,\n",
    "                                         num_workers=1)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the model as well as its forward pass function. This is a fairly simple CNN with 2 convolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d1ea6d6-e052-48dd-93a6-b521b38dadbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,  # (int) -> number of channels in input image    =1 because output is grayscale image\n",
    "                out_channels=16, # (int) -> number of channels produced by the convolution\n",
    "                kernel_size=5, # (int, tuple) -> size of convolving kernel\n",
    "                stride=1, # (int, tuple, optional) -> stride of convolution, default is 1\n",
    "                padding=2, # (int, tuple, optional) -> zero-padding added to both sides of input, default is 0\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.out = nn.Linear(32 * 7 * 7, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        output = self.out(x)\n",
    "        return output, x       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf629382-9dc6-417d-ac6e-9bfc8d929e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define the loss function and optimizer. Cross Entropy Loss is a loss function for classification problems, while Adam is a popular and powerful optimizer that extends the already effective stochastic gradient descent algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8242ffcc-d539-4bfb-bf5c-d6a48734a9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=0.01)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worthwhile to check and make sure what device we are running on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c7e42c3-a6ff-4bf2-8952-799307d39269",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# train on the GPU or on the CPU, if a GPU is not available\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUsing device:\u001b[39m\u001b[38;5;124m'\u001b[39m, device)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# train on the GPU or on the CPU, if a GPU is not available\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next is the training step. As this is a convolutional neural network being trained on a large image dataset, expect training time to take much longer than for a simple linear regression model. It is also worthwhile to time the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "454327ee-f3f9-4250-9412-bf50c53054f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61975a57-f7ae-4a47-90ad-27f7b03b89c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step[1/600], Loss: 2.3085\n",
      "Epoch [1/10], Step[2/600], Loss: 2.3335\n",
      "Epoch [1/10], Step[3/600], Loss: 2.1627\n",
      "Epoch [1/10], Step[8/600], Loss: 0.9446\n",
      "Epoch [1/10], Step[9/600], Loss: 0.7256\n",
      "Epoch [1/10], Step[10/600], Loss: 1.0656\n",
      "Epoch [1/10], Step[11/600], Loss: 0.9062\n",
      "Epoch [1/10], Step[16/600], Loss: 0.3464\n",
      "Epoch [1/10], Step[17/600], Loss: 0.3734\n",
      "Epoch [1/10], Step[18/600], Loss: 0.3761\n",
      "Epoch [1/10], Step[19/600], Loss: 0.3033\n",
      "Epoch [1/10], Step[24/600], Loss: 0.2826\n",
      "Epoch [1/10], Step[25/600], Loss: 0.3733\n",
      "Epoch [1/10], Step[26/600], Loss: 0.3239\n",
      "Epoch [1/10], Step[27/600], Loss: 0.2235\n",
      "Epoch [1/10], Step[128/600], Loss: 0.0396\n",
      "Epoch [1/10], Step[129/600], Loss: 0.1523\n",
      "Epoch [1/10], Step[130/600], Loss: 0.0681\n",
      "Epoch [1/10], Step[131/600], Loss: 0.0908\n",
      "Epoch [1/10], Step[136/600], Loss: 0.0635\n",
      "Epoch [1/10], Step[137/600], Loss: 0.0415\n",
      "Epoch [1/10], Step[138/600], Loss: 0.0911\n",
      "Epoch [1/10], Step[139/600], Loss: 0.0752\n",
      "Epoch [1/10], Step[144/600], Loss: 0.1159\n",
      "Epoch [1/10], Step[145/600], Loss: 0.0675\n",
      "Epoch [1/10], Step[146/600], Loss: 0.0683\n",
      "Epoch [1/10], Step[147/600], Loss: 0.0877\n",
      "Epoch [1/10], Step[152/600], Loss: 0.0749\n",
      "Epoch [1/10], Step[153/600], Loss: 0.0552\n",
      "Epoch [1/10], Step[154/600], Loss: 0.1735\n",
      "Epoch [1/10], Step[155/600], Loss: 0.4248\n",
      "Epoch [1/10], Step[256/600], Loss: 0.0292\n",
      "Epoch [1/10], Step[257/600], Loss: 0.0256\n",
      "Epoch [1/10], Step[258/600], Loss: 0.0966\n",
      "Epoch [1/10], Step[259/600], Loss: 0.0674\n",
      "Epoch [1/10], Step[264/600], Loss: 0.1212\n",
      "Epoch [1/10], Step[265/600], Loss: 0.0737\n",
      "Epoch [1/10], Step[266/600], Loss: 0.0549\n",
      "Epoch [1/10], Step[267/600], Loss: 0.2259\n",
      "Epoch [1/10], Step[272/600], Loss: 0.0063\n",
      "Epoch [1/10], Step[273/600], Loss: 0.0738\n",
      "Epoch [1/10], Step[274/600], Loss: 0.0445\n",
      "Epoch [1/10], Step[275/600], Loss: 0.1086\n",
      "Epoch [1/10], Step[280/600], Loss: 0.1869\n",
      "Epoch [1/10], Step[281/600], Loss: 0.0346\n",
      "Epoch [1/10], Step[282/600], Loss: 0.0244\n",
      "Epoch [1/10], Step[283/600], Loss: 0.0151\n",
      "Epoch [1/10], Step[384/600], Loss: 0.0473\n",
      "Epoch [1/10], Step[385/600], Loss: 0.1167\n",
      "Epoch [1/10], Step[386/600], Loss: 0.0259\n",
      "Epoch [1/10], Step[387/600], Loss: 0.1701\n",
      "Epoch [1/10], Step[392/600], Loss: 0.0377\n",
      "Epoch [1/10], Step[393/600], Loss: 0.0928\n",
      "Epoch [1/10], Step[394/600], Loss: 0.0065\n",
      "Epoch [1/10], Step[395/600], Loss: 0.1018\n",
      "Epoch [1/10], Step[400/600], Loss: 0.0981\n",
      "Epoch [1/10], Step[401/600], Loss: 0.0230\n",
      "Epoch [1/10], Step[402/600], Loss: 0.0246\n",
      "Epoch [1/10], Step[403/600], Loss: 0.0437\n",
      "Epoch [1/10], Step[408/600], Loss: 0.1225\n",
      "Epoch [1/10], Step[409/600], Loss: 0.0405\n",
      "Epoch [1/10], Step[410/600], Loss: 0.0412\n",
      "Epoch [1/10], Step[411/600], Loss: 0.0677\n",
      "Epoch [1/10], Step[512/600], Loss: 0.1041\n",
      "Epoch [1/10], Step[513/600], Loss: 0.0479\n",
      "Epoch [1/10], Step[514/600], Loss: 0.0176\n",
      "Epoch [1/10], Step[515/600], Loss: 0.0421\n",
      "Epoch [1/10], Step[520/600], Loss: 0.0069\n",
      "Epoch [1/10], Step[521/600], Loss: 0.1359\n",
      "Epoch [1/10], Step[522/600], Loss: 0.0581\n",
      "Epoch [1/10], Step[523/600], Loss: 0.0398\n",
      "Epoch [1/10], Step[528/600], Loss: 0.0268\n",
      "Epoch [1/10], Step[529/600], Loss: 0.0757\n",
      "Epoch [1/10], Step[530/600], Loss: 0.0948\n",
      "Epoch [1/10], Step[531/600], Loss: 0.0911\n",
      "Epoch [1/10], Step[536/600], Loss: 0.0097\n",
      "Epoch [1/10], Step[537/600], Loss: 0.1507\n",
      "Epoch [1/10], Step[538/600], Loss: 0.1431\n",
      "Epoch [1/10], Step[539/600], Loss: 0.0169\n",
      "Epoch [2/10], Step[1/600], Loss: 0.0827\n",
      "Epoch [2/10], Step[2/600], Loss: 0.0223\n",
      "Epoch [2/10], Step[3/600], Loss: 0.1292\n",
      "Epoch [2/10], Step[8/600], Loss: 0.0502\n",
      "Epoch [2/10], Step[9/600], Loss: 0.0382\n",
      "Epoch [2/10], Step[10/600], Loss: 0.1570\n",
      "Epoch [2/10], Step[11/600], Loss: 0.0871\n",
      "Epoch [2/10], Step[16/600], Loss: 0.0031\n",
      "Epoch [2/10], Step[17/600], Loss: 0.0654\n",
      "Epoch [2/10], Step[18/600], Loss: 0.0244\n",
      "Epoch [2/10], Step[19/600], Loss: 0.0697\n",
      "Epoch [2/10], Step[24/600], Loss: 0.0774\n",
      "Epoch [2/10], Step[25/600], Loss: 0.0261\n",
      "Epoch [2/10], Step[26/600], Loss: 0.0523\n",
      "Epoch [2/10], Step[27/600], Loss: 0.0074\n",
      "Epoch [2/10], Step[128/600], Loss: 0.1077\n",
      "Epoch [2/10], Step[129/600], Loss: 0.0780\n",
      "Epoch [2/10], Step[130/600], Loss: 0.0456\n",
      "Epoch [2/10], Step[131/600], Loss: 0.0298\n",
      "Epoch [2/10], Step[136/600], Loss: 0.0469\n",
      "Epoch [2/10], Step[137/600], Loss: 0.0622\n",
      "Epoch [2/10], Step[138/600], Loss: 0.0101\n",
      "Epoch [2/10], Step[139/600], Loss: 0.0716\n",
      "Epoch [2/10], Step[144/600], Loss: 0.0159\n",
      "Epoch [2/10], Step[145/600], Loss: 0.0236\n",
      "Epoch [2/10], Step[146/600], Loss: 0.0350\n",
      "Epoch [2/10], Step[147/600], Loss: 0.0053\n",
      "Epoch [2/10], Step[152/600], Loss: 0.1255\n",
      "Epoch [2/10], Step[153/600], Loss: 0.1024\n",
      "Epoch [2/10], Step[154/600], Loss: 0.0079\n",
      "Epoch [2/10], Step[155/600], Loss: 0.0084\n",
      "Epoch [2/10], Step[256/600], Loss: 0.0893\n",
      "Epoch [2/10], Step[257/600], Loss: 0.0205\n",
      "Epoch [2/10], Step[258/600], Loss: 0.0739\n",
      "Epoch [2/10], Step[259/600], Loss: 0.0067\n",
      "Epoch [2/10], Step[264/600], Loss: 0.0407\n",
      "Epoch [2/10], Step[265/600], Loss: 0.0110\n",
      "Epoch [2/10], Step[266/600], Loss: 0.0401\n",
      "Epoch [2/10], Step[267/600], Loss: 0.0518\n",
      "Epoch [2/10], Step[272/600], Loss: 0.0465\n",
      "Epoch [2/10], Step[273/600], Loss: 0.1119\n",
      "Epoch [2/10], Step[274/600], Loss: 0.0477\n",
      "Epoch [2/10], Step[275/600], Loss: 0.0136\n",
      "Epoch [2/10], Step[280/600], Loss: 0.0121\n",
      "Epoch [2/10], Step[281/600], Loss: 0.0688\n",
      "Epoch [2/10], Step[282/600], Loss: 0.0527\n",
      "Epoch [2/10], Step[283/600], Loss: 0.0516\n",
      "Epoch [2/10], Step[384/600], Loss: 0.0895\n",
      "Epoch [2/10], Step[385/600], Loss: 0.1391\n",
      "Epoch [2/10], Step[386/600], Loss: 0.0635\n",
      "Epoch [2/10], Step[387/600], Loss: 0.0385\n",
      "Epoch [2/10], Step[392/600], Loss: 0.0459\n",
      "Epoch [2/10], Step[393/600], Loss: 0.2200\n",
      "Epoch [2/10], Step[394/600], Loss: 0.1763\n",
      "Epoch [2/10], Step[395/600], Loss: 0.0265\n",
      "Epoch [2/10], Step[400/600], Loss: 0.0338\n",
      "Epoch [2/10], Step[401/600], Loss: 0.1066\n",
      "Epoch [2/10], Step[402/600], Loss: 0.0243\n",
      "Epoch [2/10], Step[403/600], Loss: 0.0526\n",
      "Epoch [2/10], Step[408/600], Loss: 0.0550\n",
      "Epoch [2/10], Step[409/600], Loss: 0.0564\n",
      "Epoch [2/10], Step[410/600], Loss: 0.0376\n",
      "Epoch [2/10], Step[411/600], Loss: 0.0516\n",
      "Epoch [2/10], Step[512/600], Loss: 0.0309\n",
      "Epoch [2/10], Step[513/600], Loss: 0.0716\n",
      "Epoch [2/10], Step[514/600], Loss: 0.0168\n",
      "Epoch [2/10], Step[515/600], Loss: 0.0577\n",
      "Epoch [2/10], Step[520/600], Loss: 0.0197\n",
      "Epoch [2/10], Step[521/600], Loss: 0.0148\n",
      "Epoch [2/10], Step[522/600], Loss: 0.0287\n",
      "Epoch [2/10], Step[523/600], Loss: 0.0455\n",
      "Epoch [2/10], Step[528/600], Loss: 0.0135\n",
      "Epoch [2/10], Step[529/600], Loss: 0.0462\n",
      "Epoch [2/10], Step[530/600], Loss: 0.0846\n",
      "Epoch [2/10], Step[531/600], Loss: 0.0167\n",
      "Epoch [2/10], Step[536/600], Loss: 0.1159\n",
      "Epoch [2/10], Step[537/600], Loss: 0.1000\n",
      "Epoch [2/10], Step[538/600], Loss: 0.0125\n",
      "Epoch [2/10], Step[539/600], Loss: 0.0795\n",
      "Epoch [3/10], Step[1/600], Loss: 0.0147\n",
      "Epoch [3/10], Step[2/600], Loss: 0.0301\n",
      "Epoch [3/10], Step[3/600], Loss: 0.0491\n",
      "Epoch [3/10], Step[8/600], Loss: 0.0046\n",
      "Epoch [3/10], Step[9/600], Loss: 0.0389\n",
      "Epoch [3/10], Step[10/600], Loss: 0.0107\n",
      "Epoch [3/10], Step[11/600], Loss: 0.0324\n",
      "Epoch [3/10], Step[16/600], Loss: 0.0465\n",
      "Epoch [3/10], Step[17/600], Loss: 0.1551\n",
      "Epoch [3/10], Step[18/600], Loss: 0.0181\n",
      "Epoch [3/10], Step[19/600], Loss: 0.0312\n",
      "Epoch [3/10], Step[24/600], Loss: 0.0020\n",
      "Epoch [3/10], Step[25/600], Loss: 0.0138\n",
      "Epoch [3/10], Step[26/600], Loss: 0.0231\n",
      "Epoch [3/10], Step[27/600], Loss: 0.0326\n",
      "Epoch [3/10], Step[128/600], Loss: 0.0118\n",
      "Epoch [3/10], Step[129/600], Loss: 0.1022\n",
      "Epoch [3/10], Step[130/600], Loss: 0.0283\n",
      "Epoch [3/10], Step[131/600], Loss: 0.0184\n",
      "Epoch [3/10], Step[136/600], Loss: 0.0323\n",
      "Epoch [3/10], Step[137/600], Loss: 0.0058\n",
      "Epoch [3/10], Step[138/600], Loss: 0.0093\n",
      "Epoch [3/10], Step[139/600], Loss: 0.0747\n",
      "Epoch [3/10], Step[144/600], Loss: 0.0156\n",
      "Epoch [3/10], Step[145/600], Loss: 0.0128\n",
      "Epoch [3/10], Step[146/600], Loss: 0.0887\n",
      "Epoch [3/10], Step[147/600], Loss: 0.0115\n",
      "Epoch [3/10], Step[152/600], Loss: 0.0538\n",
      "Epoch [3/10], Step[153/600], Loss: 0.0531\n",
      "Epoch [3/10], Step[154/600], Loss: 0.0150\n",
      "Epoch [3/10], Step[155/600], Loss: 0.0163\n",
      "Epoch [3/10], Step[256/600], Loss: 0.0898\n",
      "Epoch [3/10], Step[257/600], Loss: 0.0071\n",
      "Epoch [3/10], Step[258/600], Loss: 0.0222\n",
      "Epoch [3/10], Step[259/600], Loss: 0.0158\n",
      "Epoch [3/10], Step[264/600], Loss: 0.0065\n",
      "Epoch [3/10], Step[265/600], Loss: 0.0656\n",
      "Epoch [3/10], Step[266/600], Loss: 0.1040\n",
      "Epoch [3/10], Step[267/600], Loss: 0.0218\n",
      "Epoch [3/10], Step[272/600], Loss: 0.0293\n",
      "Epoch [3/10], Step[273/600], Loss: 0.0827\n",
      "Epoch [3/10], Step[274/600], Loss: 0.0378\n",
      "Epoch [3/10], Step[275/600], Loss: 0.1146\n",
      "Epoch [3/10], Step[280/600], Loss: 0.0131\n",
      "Epoch [3/10], Step[281/600], Loss: 0.0803\n",
      "Epoch [3/10], Step[282/600], Loss: 0.0972\n",
      "Epoch [3/10], Step[283/600], Loss: 0.0472\n",
      "Epoch [3/10], Step[384/600], Loss: 0.0538\n",
      "Epoch [3/10], Step[385/600], Loss: 0.0042\n",
      "Epoch [3/10], Step[386/600], Loss: 0.0213\n",
      "Epoch [3/10], Step[387/600], Loss: 0.0500\n",
      "Epoch [3/10], Step[392/600], Loss: 0.0728\n",
      "Epoch [3/10], Step[393/600], Loss: 0.0116\n",
      "Epoch [3/10], Step[394/600], Loss: 0.0162\n",
      "Epoch [3/10], Step[395/600], Loss: 0.0408\n",
      "Epoch [3/10], Step[400/600], Loss: 0.1074\n",
      "Epoch [3/10], Step[401/600], Loss: 0.0227\n",
      "Epoch [3/10], Step[402/600], Loss: 0.0141\n",
      "Epoch [3/10], Step[403/600], Loss: 0.0332\n",
      "Epoch [3/10], Step[408/600], Loss: 0.0396\n",
      "Epoch [3/10], Step[409/600], Loss: 0.0135\n",
      "Epoch [3/10], Step[410/600], Loss: 0.0060\n",
      "Epoch [3/10], Step[411/600], Loss: 0.0212\n",
      "Epoch [3/10], Step[512/600], Loss: 0.0122\n",
      "Epoch [3/10], Step[513/600], Loss: 0.0664\n",
      "Epoch [3/10], Step[514/600], Loss: 0.0025\n",
      "Epoch [3/10], Step[515/600], Loss: 0.0835\n",
      "Epoch [3/10], Step[520/600], Loss: 0.1245\n",
      "Epoch [3/10], Step[521/600], Loss: 0.0877\n",
      "Epoch [3/10], Step[522/600], Loss: 0.0999\n",
      "Epoch [3/10], Step[523/600], Loss: 0.0161\n",
      "Epoch [3/10], Step[528/600], Loss: 0.1811\n",
      "Epoch [3/10], Step[529/600], Loss: 0.0311\n",
      "Epoch [3/10], Step[530/600], Loss: 0.2506\n",
      "Epoch [3/10], Step[531/600], Loss: 0.0379\n",
      "Epoch [3/10], Step[536/600], Loss: 0.0316\n",
      "Epoch [3/10], Step[537/600], Loss: 0.0078\n",
      "Epoch [3/10], Step[538/600], Loss: 0.1002\n",
      "Epoch [3/10], Step[539/600], Loss: 0.2389\n",
      "Epoch [4/10], Step[1/600], Loss: 0.0407\n",
      "Epoch [4/10], Step[2/600], Loss: 0.0043\n",
      "Epoch [4/10], Step[3/600], Loss: 0.0449\n",
      "Epoch [4/10], Step[8/600], Loss: 0.0439\n",
      "Epoch [4/10], Step[9/600], Loss: 0.0836\n",
      "Epoch [4/10], Step[10/600], Loss: 0.0060\n",
      "Epoch [4/10], Step[11/600], Loss: 0.0035\n",
      "Epoch [4/10], Step[16/600], Loss: 0.0180\n",
      "Epoch [4/10], Step[17/600], Loss: 0.1052\n",
      "Epoch [4/10], Step[18/600], Loss: 0.0025\n",
      "Epoch [4/10], Step[19/600], Loss: 0.0385\n",
      "Epoch [4/10], Step[24/600], Loss: 0.0716\n",
      "Epoch [4/10], Step[25/600], Loss: 0.0916\n",
      "Epoch [4/10], Step[26/600], Loss: 0.0081\n",
      "Epoch [4/10], Step[27/600], Loss: 0.0632\n",
      "Epoch [4/10], Step[128/600], Loss: 0.0286\n",
      "Epoch [4/10], Step[129/600], Loss: 0.0050\n",
      "Epoch [4/10], Step[130/600], Loss: 0.0030\n",
      "Epoch [4/10], Step[131/600], Loss: 0.0071\n",
      "Epoch [4/10], Step[136/600], Loss: 0.0053\n",
      "Epoch [4/10], Step[137/600], Loss: 0.0524\n",
      "Epoch [4/10], Step[138/600], Loss: 0.0312\n",
      "Epoch [4/10], Step[139/600], Loss: 0.0097\n",
      "Epoch [4/10], Step[144/600], Loss: 0.1377\n",
      "Epoch [4/10], Step[145/600], Loss: 0.1824\n",
      "Epoch [4/10], Step[146/600], Loss: 0.0424\n",
      "Epoch [4/10], Step[147/600], Loss: 0.0079\n",
      "Epoch [4/10], Step[152/600], Loss: 0.0605\n",
      "Epoch [4/10], Step[153/600], Loss: 0.0040\n",
      "Epoch [4/10], Step[154/600], Loss: 0.0448\n",
      "Epoch [4/10], Step[155/600], Loss: 0.0526\n",
      "Epoch [4/10], Step[256/600], Loss: 0.0327\n",
      "Epoch [4/10], Step[257/600], Loss: 0.0916\n",
      "Epoch [4/10], Step[258/600], Loss: 0.0471\n",
      "Epoch [4/10], Step[259/600], Loss: 0.1124\n",
      "Epoch [4/10], Step[264/600], Loss: 0.0171\n",
      "Epoch [4/10], Step[265/600], Loss: 0.0307\n",
      "Epoch [4/10], Step[266/600], Loss: 0.0242\n",
      "Epoch [4/10], Step[267/600], Loss: 0.0204\n",
      "Epoch [4/10], Step[272/600], Loss: 0.0214\n",
      "Epoch [4/10], Step[273/600], Loss: 0.0252\n",
      "Epoch [4/10], Step[274/600], Loss: 0.0842\n",
      "Epoch [4/10], Step[275/600], Loss: 0.0164\n",
      "Epoch [4/10], Step[280/600], Loss: 0.0661\n",
      "Epoch [4/10], Step[281/600], Loss: 0.0110\n",
      "Epoch [4/10], Step[282/600], Loss: 0.0070\n",
      "Epoch [4/10], Step[283/600], Loss: 0.0139\n",
      "Epoch [4/10], Step[384/600], Loss: 0.0255\n",
      "Epoch [4/10], Step[385/600], Loss: 0.0826\n",
      "Epoch [4/10], Step[386/600], Loss: 0.0343\n",
      "Epoch [4/10], Step[387/600], Loss: 0.0158\n",
      "Epoch [4/10], Step[392/600], Loss: 0.0492\n",
      "Epoch [4/10], Step[393/600], Loss: 0.0108\n",
      "Epoch [4/10], Step[394/600], Loss: 0.0161\n",
      "Epoch [4/10], Step[395/600], Loss: 0.0030\n",
      "Epoch [4/10], Step[400/600], Loss: 0.0916\n",
      "Epoch [4/10], Step[401/600], Loss: 0.0406\n",
      "Epoch [4/10], Step[402/600], Loss: 0.0764\n",
      "Epoch [4/10], Step[403/600], Loss: 0.0858\n",
      "Epoch [4/10], Step[408/600], Loss: 0.0009\n",
      "Epoch [4/10], Step[409/600], Loss: 0.0157\n",
      "Epoch [4/10], Step[410/600], Loss: 0.1153\n",
      "Epoch [4/10], Step[411/600], Loss: 0.0039\n",
      "Epoch [4/10], Step[512/600], Loss: 0.0247\n",
      "Epoch [4/10], Step[513/600], Loss: 0.0037\n",
      "Epoch [4/10], Step[514/600], Loss: 0.0010\n",
      "Epoch [4/10], Step[515/600], Loss: 0.0158\n",
      "Epoch [4/10], Step[520/600], Loss: 0.1089\n",
      "Epoch [4/10], Step[521/600], Loss: 0.0111\n",
      "Epoch [4/10], Step[522/600], Loss: 0.0087\n",
      "Epoch [4/10], Step[523/600], Loss: 0.0022\n",
      "Epoch [4/10], Step[528/600], Loss: 0.0015\n",
      "Epoch [4/10], Step[529/600], Loss: 0.0081\n",
      "Epoch [4/10], Step[530/600], Loss: 0.0548\n",
      "Epoch [4/10], Step[531/600], Loss: 0.1319\n",
      "Epoch [4/10], Step[536/600], Loss: 0.0042\n",
      "Epoch [4/10], Step[537/600], Loss: 0.0034\n",
      "Epoch [4/10], Step[538/600], Loss: 0.0400\n",
      "Epoch [4/10], Step[539/600], Loss: 0.0757\n",
      "Epoch [5/10], Step[1/600], Loss: 0.0082\n",
      "Epoch [5/10], Step[2/600], Loss: 0.0155\n",
      "Epoch [5/10], Step[3/600], Loss: 0.0927\n",
      "Epoch [5/10], Step[8/600], Loss: 0.0332\n",
      "Epoch [5/10], Step[9/600], Loss: 0.0020\n",
      "Epoch [5/10], Step[10/600], Loss: 0.0275\n",
      "Epoch [5/10], Step[11/600], Loss: 0.0149\n",
      "Epoch [5/10], Step[16/600], Loss: 0.0122\n",
      "Epoch [5/10], Step[17/600], Loss: 0.0084\n",
      "Epoch [5/10], Step[18/600], Loss: 0.0115\n",
      "Epoch [5/10], Step[19/600], Loss: 0.0465\n",
      "Epoch [5/10], Step[24/600], Loss: 0.0157\n",
      "Epoch [5/10], Step[25/600], Loss: 0.0190\n",
      "Epoch [5/10], Step[26/600], Loss: 0.0171\n",
      "Epoch [5/10], Step[27/600], Loss: 0.0564\n",
      "Epoch [5/10], Step[128/600], Loss: 0.0566\n",
      "Epoch [5/10], Step[129/600], Loss: 0.0508\n",
      "Epoch [5/10], Step[130/600], Loss: 0.0616\n",
      "Epoch [5/10], Step[131/600], Loss: 0.0061\n",
      "Epoch [5/10], Step[136/600], Loss: 0.1171\n",
      "Epoch [5/10], Step[137/600], Loss: 0.0316\n",
      "Epoch [5/10], Step[138/600], Loss: 0.0683\n",
      "Epoch [5/10], Step[139/600], Loss: 0.0270\n",
      "Epoch [5/10], Step[144/600], Loss: 0.1274\n",
      "Epoch [5/10], Step[145/600], Loss: 0.0005\n",
      "Epoch [5/10], Step[146/600], Loss: 0.0085\n",
      "Epoch [5/10], Step[147/600], Loss: 0.0184\n",
      "Epoch [5/10], Step[152/600], Loss: 0.0044\n",
      "Epoch [5/10], Step[153/600], Loss: 0.0244\n",
      "Epoch [5/10], Step[154/600], Loss: 0.0204\n",
      "Epoch [5/10], Step[155/600], Loss: 0.0593\n",
      "Epoch [5/10], Step[256/600], Loss: 0.0001\n",
      "Epoch [5/10], Step[257/600], Loss: 0.0416\n",
      "Epoch [5/10], Step[258/600], Loss: 0.0572\n",
      "Epoch [5/10], Step[259/600], Loss: 0.0611\n",
      "Epoch [5/10], Step[264/600], Loss: 0.0333\n",
      "Epoch [5/10], Step[265/600], Loss: 0.0171\n",
      "Epoch [5/10], Step[266/600], Loss: 0.0071\n",
      "Epoch [5/10], Step[267/600], Loss: 0.0008\n",
      "Epoch [5/10], Step[272/600], Loss: 0.0159\n",
      "Epoch [5/10], Step[273/600], Loss: 0.0587\n",
      "Epoch [5/10], Step[274/600], Loss: 0.0687\n",
      "Epoch [5/10], Step[275/600], Loss: 0.0192\n",
      "Epoch [5/10], Step[280/600], Loss: 0.0264\n",
      "Epoch [5/10], Step[281/600], Loss: 0.0014\n",
      "Epoch [5/10], Step[282/600], Loss: 0.0161\n",
      "Epoch [5/10], Step[283/600], Loss: 0.0269\n",
      "Epoch [5/10], Step[384/600], Loss: 0.1250\n",
      "Epoch [5/10], Step[385/600], Loss: 0.0107\n",
      "Epoch [5/10], Step[386/600], Loss: 0.0150\n",
      "Epoch [5/10], Step[387/600], Loss: 0.0676\n",
      "Epoch [5/10], Step[392/600], Loss: 0.0272\n",
      "Epoch [5/10], Step[393/600], Loss: 0.0379\n",
      "Epoch [5/10], Step[394/600], Loss: 0.0157\n",
      "Epoch [5/10], Step[395/600], Loss: 0.0010\n",
      "Epoch [5/10], Step[400/600], Loss: 0.0029\n",
      "Epoch [5/10], Step[401/600], Loss: 0.0256\n",
      "Epoch [5/10], Step[402/600], Loss: 0.0068\n",
      "Epoch [5/10], Step[403/600], Loss: 0.0345\n",
      "Epoch [5/10], Step[408/600], Loss: 0.0024\n",
      "Epoch [5/10], Step[409/600], Loss: 0.0310\n",
      "Epoch [5/10], Step[410/600], Loss: 0.0026\n",
      "Epoch [5/10], Step[411/600], Loss: 0.0968\n",
      "Epoch [5/10], Step[512/600], Loss: 0.1773\n",
      "Epoch [5/10], Step[513/600], Loss: 0.1042\n",
      "Epoch [5/10], Step[514/600], Loss: 0.0134\n",
      "Epoch [5/10], Step[515/600], Loss: 0.0712\n",
      "Epoch [5/10], Step[520/600], Loss: 0.0106\n",
      "Epoch [5/10], Step[521/600], Loss: 0.0963\n",
      "Epoch [5/10], Step[522/600], Loss: 0.1066\n",
      "Epoch [5/10], Step[523/600], Loss: 0.0121\n",
      "Epoch [5/10], Step[528/600], Loss: 0.0919\n",
      "Epoch [5/10], Step[529/600], Loss: 0.0772\n",
      "Epoch [5/10], Step[530/600], Loss: 0.1148\n",
      "Epoch [5/10], Step[531/600], Loss: 0.0151\n",
      "Epoch [5/10], Step[536/600], Loss: 0.0498\n",
      "Epoch [5/10], Step[537/600], Loss: 0.0097\n",
      "Epoch [5/10], Step[538/600], Loss: 0.1606\n",
      "Epoch [5/10], Step[539/600], Loss: 0.2888\n",
      "Epoch [6/10], Step[1/600], Loss: 0.0443\n",
      "Epoch [6/10], Step[2/600], Loss: 0.0030\n",
      "Epoch [6/10], Step[3/600], Loss: 0.0131\n",
      "Epoch [6/10], Step[8/600], Loss: 0.0084\n",
      "Epoch [6/10], Step[9/600], Loss: 0.0836\n",
      "Epoch [6/10], Step[10/600], Loss: 0.0513\n",
      "Epoch [6/10], Step[11/600], Loss: 0.0664\n",
      "Epoch [6/10], Step[16/600], Loss: 0.0302\n",
      "Epoch [6/10], Step[17/600], Loss: 0.0824\n",
      "Epoch [6/10], Step[18/600], Loss: 0.0053\n",
      "Epoch [6/10], Step[19/600], Loss: 0.0086\n",
      "Epoch [6/10], Step[24/600], Loss: 0.0451\n",
      "Epoch [6/10], Step[25/600], Loss: 0.0369\n",
      "Epoch [6/10], Step[26/600], Loss: 0.0376\n",
      "Epoch [6/10], Step[27/600], Loss: 0.0132\n",
      "Epoch [6/10], Step[128/600], Loss: 0.0312\n",
      "Epoch [6/10], Step[129/600], Loss: 0.0282\n",
      "Epoch [6/10], Step[130/600], Loss: 0.0206\n",
      "Epoch [6/10], Step[131/600], Loss: 0.0039\n",
      "Epoch [6/10], Step[136/600], Loss: 0.0318\n",
      "Epoch [6/10], Step[137/600], Loss: 0.0101\n",
      "Epoch [6/10], Step[138/600], Loss: 0.0014\n",
      "Epoch [6/10], Step[139/600], Loss: 0.0076\n",
      "Epoch [6/10], Step[144/600], Loss: 0.0046\n",
      "Epoch [6/10], Step[145/600], Loss: 0.0389\n",
      "Epoch [6/10], Step[146/600], Loss: 0.0431\n",
      "Epoch [6/10], Step[147/600], Loss: 0.0157\n",
      "Epoch [6/10], Step[152/600], Loss: 0.0017\n",
      "Epoch [6/10], Step[153/600], Loss: 0.0177\n",
      "Epoch [6/10], Step[154/600], Loss: 0.0159\n",
      "Epoch [6/10], Step[155/600], Loss: 0.0195\n",
      "Epoch [6/10], Step[256/600], Loss: 0.0317\n",
      "Epoch [6/10], Step[257/600], Loss: 0.1514\n",
      "Epoch [6/10], Step[258/600], Loss: 0.0325\n",
      "Epoch [6/10], Step[259/600], Loss: 0.0173\n",
      "Epoch [6/10], Step[264/600], Loss: 0.0004\n",
      "Epoch [6/10], Step[265/600], Loss: 0.0341\n",
      "Epoch [6/10], Step[266/600], Loss: 0.0850\n",
      "Epoch [6/10], Step[267/600], Loss: 0.0074\n",
      "Epoch [6/10], Step[272/600], Loss: 0.0393\n",
      "Epoch [6/10], Step[273/600], Loss: 0.0218\n",
      "Epoch [6/10], Step[274/600], Loss: 0.0072\n",
      "Epoch [6/10], Step[275/600], Loss: 0.0016\n",
      "Epoch [6/10], Step[280/600], Loss: 0.0168\n",
      "Epoch [6/10], Step[281/600], Loss: 0.0608\n",
      "Epoch [6/10], Step[282/600], Loss: 0.0221\n",
      "Epoch [6/10], Step[283/600], Loss: 0.0049\n",
      "Epoch [6/10], Step[384/600], Loss: 0.0759\n",
      "Epoch [6/10], Step[385/600], Loss: 0.1255\n",
      "Epoch [6/10], Step[386/600], Loss: 0.0091\n",
      "Epoch [6/10], Step[387/600], Loss: 0.0216\n",
      "Epoch [6/10], Step[392/600], Loss: 0.0029\n",
      "Epoch [6/10], Step[393/600], Loss: 0.0022\n",
      "Epoch [6/10], Step[394/600], Loss: 0.0041\n",
      "Epoch [6/10], Step[395/600], Loss: 0.0007\n",
      "Epoch [6/10], Step[400/600], Loss: 0.0779\n",
      "Epoch [6/10], Step[401/600], Loss: 0.0026\n",
      "Epoch [6/10], Step[402/600], Loss: 0.0165\n",
      "Epoch [6/10], Step[403/600], Loss: 0.0361\n",
      "Epoch [6/10], Step[408/600], Loss: 0.1751\n",
      "Epoch [6/10], Step[409/600], Loss: 0.0634\n",
      "Epoch [6/10], Step[410/600], Loss: 0.0008\n",
      "Epoch [6/10], Step[411/600], Loss: 0.0002\n",
      "Epoch [6/10], Step[512/600], Loss: 0.0243\n",
      "Epoch [6/10], Step[513/600], Loss: 0.0062\n",
      "Epoch [6/10], Step[514/600], Loss: 0.0151\n",
      "Epoch [6/10], Step[515/600], Loss: 0.0310\n",
      "Epoch [6/10], Step[520/600], Loss: 0.0015\n",
      "Epoch [6/10], Step[521/600], Loss: 0.0357\n",
      "Epoch [6/10], Step[522/600], Loss: 0.0029\n",
      "Epoch [6/10], Step[523/600], Loss: 0.0391\n",
      "Epoch [6/10], Step[528/600], Loss: 0.0086\n",
      "Epoch [6/10], Step[529/600], Loss: 0.0185\n",
      "Epoch [6/10], Step[530/600], Loss: 0.0003\n",
      "Epoch [6/10], Step[531/600], Loss: 0.0467\n",
      "Epoch [6/10], Step[536/600], Loss: 0.0097\n",
      "Epoch [6/10], Step[537/600], Loss: 0.0141\n",
      "Epoch [6/10], Step[538/600], Loss: 0.0997\n",
      "Epoch [6/10], Step[539/600], Loss: 0.0512\n",
      "Epoch [7/10], Step[1/600], Loss: 0.0262\n",
      "Epoch [7/10], Step[2/600], Loss: 0.0061\n",
      "Epoch [7/10], Step[3/600], Loss: 0.0053\n",
      "Epoch [7/10], Step[8/600], Loss: 0.0064\n",
      "Epoch [7/10], Step[9/600], Loss: 0.0164\n",
      "Epoch [7/10], Step[10/600], Loss: 0.0287\n",
      "Epoch [7/10], Step[11/600], Loss: 0.0138\n",
      "Epoch [7/10], Step[16/600], Loss: 0.0110\n",
      "Epoch [7/10], Step[17/600], Loss: 0.0301\n",
      "Epoch [7/10], Step[18/600], Loss: 0.0050\n",
      "Epoch [7/10], Step[19/600], Loss: 0.0481\n",
      "Epoch [7/10], Step[24/600], Loss: 0.0709\n",
      "Epoch [7/10], Step[25/600], Loss: 0.0328\n",
      "Epoch [7/10], Step[26/600], Loss: 0.0193\n",
      "Epoch [7/10], Step[27/600], Loss: 0.0021\n",
      "Epoch [7/10], Step[128/600], Loss: 0.0020\n",
      "Epoch [7/10], Step[129/600], Loss: 0.0771\n",
      "Epoch [7/10], Step[130/600], Loss: 0.0064\n",
      "Epoch [7/10], Step[131/600], Loss: 0.0259\n",
      "Epoch [7/10], Step[136/600], Loss: 0.0007\n",
      "Epoch [7/10], Step[137/600], Loss: 0.0710\n",
      "Epoch [7/10], Step[138/600], Loss: 0.0003\n",
      "Epoch [7/10], Step[139/600], Loss: 0.0001\n",
      "Epoch [7/10], Step[144/600], Loss: 0.0061\n",
      "Epoch [7/10], Step[145/600], Loss: 0.0103\n",
      "Epoch [7/10], Step[146/600], Loss: 0.0004\n",
      "Epoch [7/10], Step[147/600], Loss: 0.0078\n",
      "Epoch [7/10], Step[152/600], Loss: 0.0007\n",
      "Epoch [7/10], Step[153/600], Loss: 0.0001\n",
      "Epoch [7/10], Step[154/600], Loss: 0.0160\n",
      "Epoch [7/10], Step[155/600], Loss: 0.0860\n",
      "Epoch [7/10], Step[256/600], Loss: 0.0344\n",
      "Epoch [7/10], Step[257/600], Loss: 0.0264\n",
      "Epoch [7/10], Step[258/600], Loss: 0.0032\n",
      "Epoch [7/10], Step[259/600], Loss: 0.0029\n",
      "Epoch [7/10], Step[264/600], Loss: 0.0131\n",
      "Epoch [7/10], Step[265/600], Loss: 0.0067\n",
      "Epoch [7/10], Step[266/600], Loss: 0.0176\n",
      "Epoch [7/10], Step[267/600], Loss: 0.0016\n",
      "Epoch [7/10], Step[272/600], Loss: 0.0046\n",
      "Epoch [7/10], Step[273/600], Loss: 0.1155\n",
      "Epoch [7/10], Step[274/600], Loss: 0.0990\n",
      "Epoch [7/10], Step[275/600], Loss: 0.0529\n",
      "Epoch [7/10], Step[280/600], Loss: 0.0214\n",
      "Epoch [7/10], Step[281/600], Loss: 0.0316\n",
      "Epoch [7/10], Step[282/600], Loss: 0.0593\n",
      "Epoch [7/10], Step[283/600], Loss: 0.0603\n",
      "Epoch [7/10], Step[384/600], Loss: 0.0032\n",
      "Epoch [7/10], Step[385/600], Loss: 0.0062\n",
      "Epoch [7/10], Step[386/600], Loss: 0.0229\n",
      "Epoch [7/10], Step[387/600], Loss: 0.0549\n",
      "Epoch [7/10], Step[392/600], Loss: 0.0017\n",
      "Epoch [7/10], Step[393/600], Loss: 0.0232\n",
      "Epoch [7/10], Step[394/600], Loss: 0.0348\n",
      "Epoch [7/10], Step[395/600], Loss: 0.0049\n",
      "Epoch [7/10], Step[400/600], Loss: 0.0006\n",
      "Epoch [7/10], Step[401/600], Loss: 0.0014\n",
      "Epoch [7/10], Step[402/600], Loss: 0.0379\n",
      "Epoch [7/10], Step[403/600], Loss: 0.0290\n",
      "Epoch [7/10], Step[408/600], Loss: 0.0405\n",
      "Epoch [7/10], Step[409/600], Loss: 0.0321\n",
      "Epoch [7/10], Step[410/600], Loss: 0.0147\n",
      "Epoch [7/10], Step[411/600], Loss: 0.0065\n",
      "Epoch [7/10], Step[512/600], Loss: 0.1040\n",
      "Epoch [7/10], Step[513/600], Loss: 0.0071\n",
      "Epoch [7/10], Step[514/600], Loss: 0.1166\n",
      "Epoch [7/10], Step[515/600], Loss: 0.0444\n",
      "Epoch [7/10], Step[520/600], Loss: 0.0402\n",
      "Epoch [7/10], Step[521/600], Loss: 0.0200\n",
      "Epoch [7/10], Step[522/600], Loss: 0.0148\n",
      "Epoch [7/10], Step[523/600], Loss: 0.0485\n",
      "Epoch [7/10], Step[528/600], Loss: 0.0362\n",
      "Epoch [7/10], Step[529/600], Loss: 0.0049\n",
      "Epoch [7/10], Step[530/600], Loss: 0.0840\n",
      "Epoch [7/10], Step[531/600], Loss: 0.4108\n",
      "Epoch [7/10], Step[536/600], Loss: 0.0648\n",
      "Epoch [7/10], Step[537/600], Loss: 0.0071\n",
      "Epoch [7/10], Step[538/600], Loss: 0.0345\n",
      "Epoch [7/10], Step[539/600], Loss: 0.1497\n",
      "Epoch [8/10], Step[1/600], Loss: 0.0007\n",
      "Epoch [8/10], Step[2/600], Loss: 0.0302\n",
      "Epoch [8/10], Step[3/600], Loss: 0.0730\n",
      "Epoch [8/10], Step[8/600], Loss: 0.0512\n",
      "Epoch [8/10], Step[9/600], Loss: 0.0995\n",
      "Epoch [8/10], Step[10/600], Loss: 0.0030\n",
      "Epoch [8/10], Step[11/600], Loss: 0.0199\n",
      "Epoch [8/10], Step[16/600], Loss: 0.0267\n",
      "Epoch [8/10], Step[17/600], Loss: 0.0148\n",
      "Epoch [8/10], Step[18/600], Loss: 0.0737\n",
      "Epoch [8/10], Step[19/600], Loss: 0.0050\n",
      "Epoch [8/10], Step[24/600], Loss: 0.0130\n",
      "Epoch [8/10], Step[25/600], Loss: 0.0481\n",
      "Epoch [8/10], Step[26/600], Loss: 0.0060\n",
      "Epoch [8/10], Step[27/600], Loss: 0.0408\n",
      "Epoch [8/10], Step[128/600], Loss: 0.1247\n",
      "Epoch [8/10], Step[129/600], Loss: 0.0829\n",
      "Epoch [8/10], Step[130/600], Loss: 0.0176\n",
      "Epoch [8/10], Step[131/600], Loss: 0.0001\n",
      "Epoch [8/10], Step[136/600], Loss: 0.0382\n",
      "Epoch [8/10], Step[137/600], Loss: 0.0056\n",
      "Epoch [8/10], Step[138/600], Loss: 0.1552\n",
      "Epoch [8/10], Step[139/600], Loss: 0.0001\n",
      "Epoch [8/10], Step[144/600], Loss: 0.0173\n",
      "Epoch [8/10], Step[145/600], Loss: 0.0001\n",
      "Epoch [8/10], Step[146/600], Loss: 0.0075\n",
      "Epoch [8/10], Step[147/600], Loss: 0.0187\n",
      "Epoch [8/10], Step[152/600], Loss: 0.0014\n",
      "Epoch [8/10], Step[153/600], Loss: 0.0342\n",
      "Epoch [8/10], Step[154/600], Loss: 0.0970\n",
      "Epoch [8/10], Step[155/600], Loss: 0.0016\n",
      "Epoch [8/10], Step[256/600], Loss: 0.0128\n",
      "Epoch [8/10], Step[257/600], Loss: 0.1820\n",
      "Epoch [8/10], Step[258/600], Loss: 0.0958\n",
      "Epoch [8/10], Step[259/600], Loss: 0.0015\n",
      "Epoch [8/10], Step[264/600], Loss: 0.0075\n",
      "Epoch [8/10], Step[265/600], Loss: 0.0115\n",
      "Epoch [8/10], Step[266/600], Loss: 0.0357\n",
      "Epoch [8/10], Step[267/600], Loss: 0.1135\n",
      "Epoch [8/10], Step[272/600], Loss: 0.0331\n",
      "Epoch [8/10], Step[273/600], Loss: 0.0004\n",
      "Epoch [8/10], Step[274/600], Loss: 0.0414\n",
      "Epoch [8/10], Step[275/600], Loss: 0.0010\n",
      "Epoch [8/10], Step[280/600], Loss: 0.0129\n",
      "Epoch [8/10], Step[281/600], Loss: 0.0490\n",
      "Epoch [8/10], Step[282/600], Loss: 0.0475\n",
      "Epoch [8/10], Step[283/600], Loss: 0.1152\n",
      "Epoch [8/10], Step[384/600], Loss: 0.0016\n",
      "Epoch [8/10], Step[385/600], Loss: 0.0758\n",
      "Epoch [8/10], Step[386/600], Loss: 0.0304\n",
      "Epoch [8/10], Step[387/600], Loss: 0.0110\n",
      "Epoch [8/10], Step[392/600], Loss: 0.1102\n",
      "Epoch [8/10], Step[393/600], Loss: 0.0139\n",
      "Epoch [8/10], Step[394/600], Loss: 0.0177\n",
      "Epoch [8/10], Step[395/600], Loss: 0.0671\n",
      "Epoch [8/10], Step[400/600], Loss: 0.0002\n",
      "Epoch [8/10], Step[401/600], Loss: 0.0016\n",
      "Epoch [8/10], Step[402/600], Loss: 0.0223\n",
      "Epoch [8/10], Step[403/600], Loss: 0.0306\n",
      "Epoch [8/10], Step[408/600], Loss: 0.0013\n",
      "Epoch [8/10], Step[409/600], Loss: 0.0005\n",
      "Epoch [8/10], Step[410/600], Loss: 0.0007\n",
      "Epoch [8/10], Step[411/600], Loss: 0.0001\n",
      "Epoch [8/10], Step[512/600], Loss: 0.0288\n",
      "Epoch [8/10], Step[513/600], Loss: 0.0231\n",
      "Epoch [8/10], Step[514/600], Loss: 0.0077\n",
      "Epoch [8/10], Step[515/600], Loss: 0.0718\n",
      "Epoch [8/10], Step[520/600], Loss: 0.1303\n",
      "Epoch [8/10], Step[521/600], Loss: 0.0574\n",
      "Epoch [8/10], Step[522/600], Loss: 0.0275\n",
      "Epoch [8/10], Step[523/600], Loss: 0.0538\n",
      "Epoch [8/10], Step[528/600], Loss: 0.0491\n",
      "Epoch [8/10], Step[529/600], Loss: 0.0004\n",
      "Epoch [8/10], Step[530/600], Loss: 0.0032\n",
      "Epoch [8/10], Step[531/600], Loss: 0.0312\n",
      "Epoch [8/10], Step[536/600], Loss: 0.0600\n",
      "Epoch [8/10], Step[537/600], Loss: 0.0008\n",
      "Epoch [8/10], Step[538/600], Loss: 0.0175\n",
      "Epoch [8/10], Step[539/600], Loss: 0.1137\n",
      "Epoch [9/10], Step[1/600], Loss: 0.0405\n",
      "Epoch [9/10], Step[2/600], Loss: 0.0005\n",
      "Epoch [9/10], Step[3/600], Loss: 0.0163\n",
      "Epoch [9/10], Step[8/600], Loss: 0.0151\n",
      "Epoch [9/10], Step[9/600], Loss: 0.0007\n",
      "Epoch [9/10], Step[10/600], Loss: 0.0802\n",
      "Epoch [9/10], Step[11/600], Loss: 0.0446\n",
      "Epoch [9/10], Step[16/600], Loss: 0.0068\n",
      "Epoch [9/10], Step[17/600], Loss: 0.0055\n",
      "Epoch [9/10], Step[18/600], Loss: 0.0006\n",
      "Epoch [9/10], Step[19/600], Loss: 0.0002\n",
      "Epoch [9/10], Step[24/600], Loss: 0.0049\n",
      "Epoch [9/10], Step[25/600], Loss: 0.0483\n",
      "Epoch [9/10], Step[26/600], Loss: 0.1608\n",
      "Epoch [9/10], Step[27/600], Loss: 0.0041\n",
      "Epoch [9/10], Step[128/600], Loss: 0.0588\n",
      "Epoch [9/10], Step[129/600], Loss: 0.0061\n",
      "Epoch [9/10], Step[130/600], Loss: 0.0013\n",
      "Epoch [9/10], Step[131/600], Loss: 0.0177\n",
      "Epoch [9/10], Step[136/600], Loss: 0.0002\n",
      "Epoch [9/10], Step[137/600], Loss: 0.0005\n",
      "Epoch [9/10], Step[138/600], Loss: 0.0001\n",
      "Epoch [9/10], Step[139/600], Loss: 0.0396\n",
      "Epoch [9/10], Step[144/600], Loss: 0.0016\n",
      "Epoch [9/10], Step[145/600], Loss: 0.0319\n",
      "Epoch [9/10], Step[146/600], Loss: 0.0238\n",
      "Epoch [9/10], Step[147/600], Loss: 0.0414\n",
      "Epoch [9/10], Step[152/600], Loss: 0.0228\n",
      "Epoch [9/10], Step[153/600], Loss: 0.0047\n",
      "Epoch [9/10], Step[154/600], Loss: 0.0013\n",
      "Epoch [9/10], Step[155/600], Loss: 0.0258\n",
      "Epoch [9/10], Step[256/600], Loss: 0.0020\n",
      "Epoch [9/10], Step[257/600], Loss: 0.0176\n",
      "Epoch [9/10], Step[258/600], Loss: 0.0804\n",
      "Epoch [9/10], Step[259/600], Loss: 0.0075\n",
      "Epoch [9/10], Step[264/600], Loss: 0.0143\n",
      "Epoch [9/10], Step[265/600], Loss: 0.0391\n",
      "Epoch [9/10], Step[266/600], Loss: 0.0074\n",
      "Epoch [9/10], Step[267/600], Loss: 0.0596\n",
      "Epoch [9/10], Step[272/600], Loss: 0.0002\n",
      "Epoch [9/10], Step[273/600], Loss: 0.0463\n",
      "Epoch [9/10], Step[274/600], Loss: 0.0512\n",
      "Epoch [9/10], Step[275/600], Loss: 0.0010\n",
      "Epoch [9/10], Step[280/600], Loss: 0.1534\n",
      "Epoch [9/10], Step[281/600], Loss: 0.0000\n",
      "Epoch [9/10], Step[282/600], Loss: 0.0553\n",
      "Epoch [9/10], Step[283/600], Loss: 0.0010\n",
      "Epoch [9/10], Step[384/600], Loss: 0.0366\n",
      "Epoch [9/10], Step[385/600], Loss: 0.0161\n",
      "Epoch [9/10], Step[386/600], Loss: 0.0363\n",
      "Epoch [9/10], Step[387/600], Loss: 0.0018\n",
      "Epoch [9/10], Step[392/600], Loss: 0.1325\n",
      "Epoch [9/10], Step[393/600], Loss: 0.0094\n",
      "Epoch [9/10], Step[394/600], Loss: 0.0419\n",
      "Epoch [9/10], Step[395/600], Loss: 0.2866\n",
      "Epoch [9/10], Step[400/600], Loss: 0.0239\n",
      "Epoch [9/10], Step[401/600], Loss: 0.0052\n",
      "Epoch [9/10], Step[402/600], Loss: 0.1471\n",
      "Epoch [9/10], Step[403/600], Loss: 0.0269\n",
      "Epoch [9/10], Step[408/600], Loss: 0.0336\n",
      "Epoch [9/10], Step[409/600], Loss: 0.1046\n",
      "Epoch [9/10], Step[410/600], Loss: 0.0025\n",
      "Epoch [9/10], Step[411/600], Loss: 0.0319\n",
      "Epoch [9/10], Step[512/600], Loss: 0.0115\n",
      "Epoch [9/10], Step[513/600], Loss: 0.0270\n",
      "Epoch [9/10], Step[514/600], Loss: 0.0002\n",
      "Epoch [9/10], Step[515/600], Loss: 0.0078\n",
      "Epoch [9/10], Step[520/600], Loss: 0.0124\n",
      "Epoch [9/10], Step[521/600], Loss: 0.0065\n",
      "Epoch [9/10], Step[522/600], Loss: 0.0051\n",
      "Epoch [9/10], Step[523/600], Loss: 0.0098\n",
      "Epoch [9/10], Step[528/600], Loss: 0.0253\n",
      "Epoch [9/10], Step[529/600], Loss: 0.0029\n",
      "Epoch [9/10], Step[530/600], Loss: 0.0852\n",
      "Epoch [9/10], Step[531/600], Loss: 0.0220\n",
      "Epoch [9/10], Step[536/600], Loss: 0.0027\n",
      "Epoch [9/10], Step[537/600], Loss: 0.0000\n",
      "Epoch [9/10], Step[538/600], Loss: 0.0001\n",
      "Epoch [9/10], Step[539/600], Loss: 0.0296\n",
      "Epoch [10/10], Step[1/600], Loss: 0.0311\n",
      "Epoch [10/10], Step[2/600], Loss: 0.0006\n",
      "Epoch [10/10], Step[3/600], Loss: 0.1568\n",
      "Epoch [10/10], Step[8/600], Loss: 0.0415\n",
      "Epoch [10/10], Step[9/600], Loss: 0.0003\n",
      "Epoch [10/10], Step[10/600], Loss: 0.0221\n",
      "Epoch [10/10], Step[11/600], Loss: 0.0201\n",
      "Epoch [10/10], Step[16/600], Loss: 0.0240\n",
      "Epoch [10/10], Step[17/600], Loss: 0.0007\n",
      "Epoch [10/10], Step[18/600], Loss: 0.0002\n",
      "Epoch [10/10], Step[19/600], Loss: 0.0051\n",
      "Epoch [10/10], Step[24/600], Loss: 0.0047\n",
      "Epoch [10/10], Step[25/600], Loss: 0.0031\n",
      "Epoch [10/10], Step[26/600], Loss: 0.0006\n",
      "Epoch [10/10], Step[27/600], Loss: 0.0040\n",
      "Epoch [10/10], Step[128/600], Loss: 0.0000\n",
      "Epoch [10/10], Step[129/600], Loss: 0.0002\n",
      "Epoch [10/10], Step[130/600], Loss: 0.0441\n",
      "Epoch [10/10], Step[131/600], Loss: 0.0047\n",
      "Epoch [10/10], Step[136/600], Loss: 0.0328\n",
      "Epoch [10/10], Step[137/600], Loss: 0.0386\n",
      "Epoch [10/10], Step[138/600], Loss: 0.0374\n",
      "Epoch [10/10], Step[139/600], Loss: 0.0015\n",
      "Epoch [10/10], Step[144/600], Loss: 0.0460\n",
      "Epoch [10/10], Step[145/600], Loss: 0.0442\n",
      "Epoch [10/10], Step[146/600], Loss: 0.0000\n",
      "Epoch [10/10], Step[147/600], Loss: 0.0352\n",
      "Epoch [10/10], Step[152/600], Loss: 0.0361\n",
      "Epoch [10/10], Step[153/600], Loss: 0.0009\n",
      "Epoch [10/10], Step[154/600], Loss: 0.0021\n",
      "Epoch [10/10], Step[155/600], Loss: 0.0870\n",
      "Epoch [10/10], Step[256/600], Loss: 0.1321\n",
      "Epoch [10/10], Step[257/600], Loss: 0.0019\n",
      "Epoch [10/10], Step[258/600], Loss: 0.0236\n",
      "Epoch [10/10], Step[259/600], Loss: 0.0533\n",
      "Epoch [10/10], Step[264/600], Loss: 0.0014\n",
      "Epoch [10/10], Step[265/600], Loss: 0.0252\n",
      "Epoch [10/10], Step[266/600], Loss: 0.1169\n",
      "Epoch [10/10], Step[267/600], Loss: 0.0657\n",
      "Epoch [10/10], Step[272/600], Loss: 0.0689\n",
      "Epoch [10/10], Step[273/600], Loss: 0.0004\n",
      "Epoch [10/10], Step[274/600], Loss: 0.0335\n",
      "Epoch [10/10], Step[275/600], Loss: 0.0752\n",
      "Epoch [10/10], Step[280/600], Loss: 0.0006\n",
      "Epoch [10/10], Step[281/600], Loss: 0.0002\n",
      "Epoch [10/10], Step[282/600], Loss: 0.0203\n",
      "Epoch [10/10], Step[283/600], Loss: 0.0264\n",
      "Epoch [10/10], Step[384/600], Loss: 0.0163\n",
      "Epoch [10/10], Step[385/600], Loss: 0.0022\n",
      "Epoch [10/10], Step[386/600], Loss: 0.0007\n",
      "Epoch [10/10], Step[387/600], Loss: 0.0022\n",
      "Epoch [10/10], Step[392/600], Loss: 0.0282\n",
      "Epoch [10/10], Step[393/600], Loss: 0.0003\n",
      "Epoch [10/10], Step[394/600], Loss: 0.0066\n",
      "Epoch [10/10], Step[395/600], Loss: 0.0309\n",
      "Epoch [10/10], Step[400/600], Loss: 0.0750\n",
      "Epoch [10/10], Step[401/600], Loss: 0.0024\n",
      "Epoch [10/10], Step[402/600], Loss: 0.1077\n",
      "Epoch [10/10], Step[403/600], Loss: 0.0043\n",
      "Epoch [10/10], Step[408/600], Loss: 0.0804\n",
      "Epoch [10/10], Step[409/600], Loss: 0.2276\n",
      "Epoch [10/10], Step[410/600], Loss: 0.0413\n",
      "Epoch [10/10], Step[411/600], Loss: 0.0034\n",
      "Epoch [10/10], Step[512/600], Loss: 0.0018\n",
      "Epoch [10/10], Step[513/600], Loss: 0.0835\n",
      "Epoch [10/10], Step[514/600], Loss: 0.0514\n",
      "Epoch [10/10], Step[515/600], Loss: 0.0491\n",
      "Epoch [10/10], Step[520/600], Loss: 0.0000\n",
      "Epoch [10/10], Step[521/600], Loss: 0.0078\n",
      "Epoch [10/10], Step[522/600], Loss: 0.0400\n",
      "Epoch [10/10], Step[523/600], Loss: 0.0310\n",
      "Epoch [10/10], Step[528/600], Loss: 0.0294\n",
      "Epoch [10/10], Step[529/600], Loss: 0.0134\n",
      "Epoch [10/10], Step[530/600], Loss: 0.0443\n",
      "Epoch [10/10], Step[531/600], Loss: 0.0971\n",
      "Epoch [10/10], Step[536/600], Loss: 0.0015\n",
      "Epoch [10/10], Step[537/600], Loss: 0.0343\n",
      "Epoch [10/10], Step[538/600], Loss: 0.0055\n",
      "Epoch [10/10], Step[539/600], Loss: 0.0038\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "def train(num_epochs, cnn, loaders):\n",
    "    cnn.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            # gives batch data, normalizes x when iterating train_loader\n",
    "            b_x = Variable(images)\n",
    "            b_y = Variable(labels)\n",
    "            \n",
    "            output = cnn(b_x)[0]\n",
    "            loss = loss_func(output, b_y)\n",
    "\n",
    "            # clear gradients for this trainign step\n",
    "            optimizer.zero_grad()\n",
    "            # backpropogation, computing gradients\n",
    "            loss.backward()\n",
    "            # apply gradients\n",
    "            optimizer.step()\n",
    "            if (i+1) & 100 == 0:\n",
    "                print('Epoch [{}/{}], Step[{}/{}], Loss: {:.4f}'\n",
    "                      .format(epoch + 1, num_epochs, i+1, total_step, loss.item()))\n",
    "                pass\n",
    "            pass\n",
    "        pass\n",
    "train(num_epochs, cnn, loaders)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68424da0-5687-4aad-977b-fe7e1057fb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 32.58645701408386 seconds\n"
     ]
    }
   ],
   "source": [
    "curr_time = time.time()\n",
    "print(f\"Training took {curr_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a testing function for model evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05c7199d-5500-4673-b8c0-488514d84edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of model on 10000 test images: 1.00\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    cnn.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in loaders['test']:\n",
    "            test_output, last_layer = cnn(images)\n",
    "            pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "            accuracy = (pred_y == labels).sum().item() / float(labels.size(0))\n",
    "            pass\n",
    "    print('Test accuracy of model on 10000 test images: %.2f' % accuracy)\n",
    "    pass\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1f7e3f7-6d92-4a70-8b45-359b8e06edcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(loaders['test']))\n",
    "imgs, lbls = sample\n",
    "actual_number = lbls[:10].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb2b657e-c7c4-40e8-be58-d32b87baa0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction number: [2 9 2 3 0 1 4 2 0 4]\n",
      "Actual number: [2 9 2 3 0 1 4 2 0 4]\n"
     ]
    }
   ],
   "source": [
    "test_output, last_layer = cnn(imgs[:10])\n",
    "pred_y = torch.max(test_output, 1)[1].data.numpy().squeeze()\n",
    "print(f'Prediction number: {pred_y}')\n",
    "print(f'Actual number: {actual_number}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can save the trained model's state using the lines below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48653cab-eb2b-4a17-85c2-57de0b4732b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to: models/01_pytorch_mnist_cnn.pth\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# 1. Create models directory \n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 2. Create model save path \n",
    "MODEL_NAME = \"01_pytorch_mnist_cnn.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "# 3. Save the model state dict \n",
    "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
    "torch.save(obj=cnn.state_dict(), # only saving the state_dict() only saves the models learned parameters\n",
    "           f=MODEL_SAVE_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3b27366-1acb-4e2a-a4e3-03667a66ffab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate a new instance of our model (this will be instantiated with random weights)\n",
    "loaded_model_0 = CNN()\n",
    "\n",
    "# Load the state_dict of our saved model (this will update the new instance of our model with trained weights)\n",
    "loaded_model_0.load_state_dict(torch.load(f=MODEL_SAVE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad626a94-4f29-4e3a-a774-5ea528848fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of model on 10000 test images: 0.99\n"
     ]
    }
   ],
   "source": [
    "loaded_model_0.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "        test_output, last_layer = loaded_model_0(images)\n",
    "        pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "        accuracy = (pred_y == labels).sum().item() / float(labels.size(0))\n",
    "        pass\n",
    "print('Test accuracy of model on 10000 test images: %.2f' % accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-0.9.4",
   "language": "python",
   "name": "python3-0.9.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
